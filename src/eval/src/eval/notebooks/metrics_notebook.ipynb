{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import polars as pl  # type: ignore\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn_polars as snl\n",
    "import seaborn as sns\n",
    "import metric_aggregation_utils\n",
    "from typing import Optional\n",
    "import yaml\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "  \n",
    "from rich import print\n",
    "\n",
    "from eval.aggregation import eval_aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "This Notebook is for aggregating `KPI` and `AVMF` metrics. For `Eval` metrics,\n",
    "see `eval_aggregation.py`. \n",
    "\n",
    "Over time, `KPI` should be phased out and `AVMF` should be aggregated similar to\n",
    "`Eval`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell tagged with `parameters` is used by papermill library to set input args.\n",
    "\n",
    "run_name: str = \"2025_03_11_test1\"\n",
    "avmf_sim_execution_table_name: Optional[str] = None\n",
    "avmf_metrics_table_name: Optional[str] = None\n",
    "kpi_sim_execution_table_name: Optional[str] = None\n",
    "kpi_metrics_table_name: Optional[str] = None\n",
    "\n",
    "route_deviation_th: float = 16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs from /wizard/configs/base_config.yaml if not specified\n",
    "config_path = \"wizard/configs/base_config.yaml\"\n",
    "current_dir = pathlib.Path(os.getcwd()).parent\n",
    "\n",
    "while not os.path.exists(current_dir / config_path):\n",
    "    current_dir = current_dir.parent\n",
    "\n",
    "if not os.path.exists(current_dir / config_path):\n",
    "    raise FileNotFoundError(f\"Could not find {config_path} in any parent directory\")\n",
    "\n",
    "config = OmegaConf.load(current_dir / config_path)\n",
    "\n",
    "avmf_sim_execution_table_name = (\n",
    "    avmf_sim_execution_table_name or config.avmf.database.sim_execution_table_name\n",
    ")\n",
    "avmf_metrics_table_name = (\n",
    "    avmf_metrics_table_name or config.avmf.database.metrics_table_name\n",
    ")\n",
    "kpi_sim_execution_table_name = (\n",
    "    kpi_sim_execution_table_name or config.kpi.database.sim_execution_table_name\n",
    ")\n",
    "kpi_metrics_table_name = (\n",
    "    kpi_metrics_table_name or config.kpi.database.metrics_table_name\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Using for AVMF: \\n\\t{avmf_sim_execution_table_name=}, \\n\\t{avmf_metrics_table_name=}\"\n",
    ")\n",
    "print(\n",
    "    f\"Using for KPI: \\n\\t{kpi_sim_execution_table_name=}, \\n\\t{kpi_metrics_table_name=}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = [\n",
    "#     \"collision\",\n",
    "#     # \"comfort_lon_accel\",\n",
    "#     # \"comfort_lat_accel\",\n",
    "#     # \"comfort_lon_jerk\",\n",
    "#     # \"comfort_jerk\",\n",
    "#     # \"comfort_yaw_rate\",\n",
    "#     # \"comfort_yaw_accel\",\n",
    "#     # \"offroad\",\n",
    "#     # \"wrong_lane\",\n",
    "#     \"stop_sign\",\n",
    "#     # Combined metrics:\n",
    "#     # \"comfort\",\n",
    "#     \"offroad_or_wrong_lane\",\n",
    "# ]\n",
    "\n",
    "collision_type_map = {\n",
    "    -1: \"No Collision\",\n",
    "    0: \"Stopped Ego Collision\",\n",
    "    1: \"Active Front Collision\",\n",
    "    2: \"Active Rear Collision\",\n",
    "    3: \"Active Lateral Collision\",\n",
    "}\n",
    "\n",
    "collisions_to_filter = [0, 2]\n",
    "\n",
    "# Regular expressions are allowed but must start with ^ and end with $.\n",
    "# Non-regular expressions are automatically excluded from regex metrics, e.g.\n",
    "# 'kpi_route_deviation' is not included in the regex metrics for min.\n",
    "metric_averaging_across_timesteps = {\n",
    "    \"max\": [\"kpi_route_deviation\"],\n",
    "    # KPI metrics are all \"lower is worse, with best value = 1\n",
    "    \"min\": [\"^kpi_.*$\"],\n",
    "    \"mean\": [\"^avmf_.*$\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avmf_metrics_table = metric_aggregation_utils.query_kratos_metrics(\n",
    "    run_name=run_name,\n",
    "    sim_execution_table_name=avmf_sim_execution_table_name,\n",
    "    metrics_table_name=avmf_metrics_table_name,\n",
    ")\n",
    "\n",
    "kpi_metrics_table = metric_aggregation_utils.query_kratos_metrics(\n",
    "    run_name=run_name,\n",
    "    sim_execution_table_name=kpi_sim_execution_table_name,\n",
    "    metrics_table_name=kpi_metrics_table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_metrics_table_df = metric_aggregation_utils.pick_relevant_kpi_columns(\n",
    "    kpi_metrics_table\n",
    ")\n",
    "events_df, per_timestep_df, per_scene_df = metric_aggregation_utils.parse_avmf_json(\n",
    "    avmf_metrics_table\n",
    ")\n",
    "avmf_per_timestep_df = metric_aggregation_utils.pick_relevant_avmf_columns(\n",
    "    per_timestep_df\n",
    ")\n",
    "\n",
    "kpi_metrics_table_df = kpi_metrics_table_df.with_columns(\n",
    "    pl.col(\"variable\").map_elements(lambda x: f\"kpi_{x}\", return_dtype=pl.Utf8)\n",
    ")\n",
    "\n",
    "avmf_per_timestep_df = avmf_per_timestep_df.with_columns(\n",
    "    pl.col(\"variable\").map_elements(lambda x: f\"avmf_{x}\", return_dtype=pl.Utf8)\n",
    ")\n",
    "\n",
    "combined_per_timestep_df = pl.concat(\n",
    "    [kpi_metrics_table_df, avmf_per_timestep_df], how=\"vertical\"\n",
    ")\n",
    "combined_per_timestep_df, trajectory_uid_df = (\n",
    "    metric_aggregation_utils.add_rollout_and_trajectory_uids(combined_per_timestep_df)\n",
    ")\n",
    "\n",
    "# Convert to wide format - easier for some computations. Sorting is important.\n",
    "df_wide = combined_per_timestep_df.pivot(\n",
    "    values=\"value\",\n",
    "    index=[\"trajectory_uid\", \"rel_timestamp\"],\n",
    "    on=\"variable\",\n",
    ").sort([\"trajectory_uid\", \"rel_timestamp\"])\n",
    "\n",
    "df_wide = metric_aggregation_utils.filter_collision_type(df_wide, collisions_to_filter)\n",
    "df_wide = metric_aggregation_utils.filter_route_deviation(df_wide, route_deviation_th)\n",
    "df_wide = metric_aggregation_utils.add_aggregate_metrics(df_wide)\n",
    "\n",
    "df_wide_avg_over_time = metric_aggregation_utils.average_metrics_across_timesteps(\n",
    "    df_wide, metric_averaging_across_timesteps\n",
    ")\n",
    "\n",
    "# Join \"run_uuid\" and \"rollout_uid\" back into the dataframe:\n",
    "df_wide_avg_over_time = df_wide_avg_over_time.join(\n",
    "    trajectory_uid_df.select(\n",
    "        pl.col(\"trajectory_uid\"), pl.col(\"rollout_uid\"), pl.col(\"run_uuid\")\n",
    "    ),\n",
    "    on=\"trajectory_uid\",\n",
    "    how=\"left\",\n",
    ").drop([\"trajectory_uid\", \"trajectory_uid_right\"])\n",
    "\n",
    "# Average over clips, `rollout_uid` is unique for each [run, batch, rollout]\n",
    "df_wide_avg = df_wide_avg_over_time.group_by(\"run_uuid\", \"rollout_uid\").agg(\n",
    "    pl.col(\"*\").mean(),\n",
    "    pl.col(\"run_uuid\").count().alias(\"num_clips\"),\n",
    ")\n",
    "\n",
    "print(\"Length after averaging over timesteps and clips: \", len(df_wide_avg))\n",
    "\n",
    "metric_aggregation_utils.save_metrics_results_txt(\n",
    "    df_wide_avg,\n",
    "    trajectory_uid_df,\n",
    "    metric_averaging_across_timesteps,\n",
    "    \"metrics_results.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = [\n",
    "    \"kpi_comfort\",\n",
    "    \"kpi_collision\",\n",
    "    \"kpi_offroad_or_wrong_lane\",\n",
    "    \"kpi_stop_sign\",\n",
    "    \"avmf_accel_x\",\n",
    "]\n",
    "df_long_avg = df_wide_avg.unpivot(\n",
    "    index=[\"run_uuid\", \"rollout_uid\"],\n",
    "    on=metrics_to_plot,\n",
    ")\n",
    "\n",
    "# We do the renamin back to run_name last and only for plotting to not\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "snl.barplot(df_long_avg, x=\"variable\", y=\"value\", hue=\"run_uuid\", errorbar=\"sd\", ax=ax)\n",
    "metric_aggregation_utils.rename_legend_handles(ax, trajectory_uid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
